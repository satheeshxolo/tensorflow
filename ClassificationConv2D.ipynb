{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassificationConv2D.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satheeshxolo/tensorflow/blob/master/ClassificationConv2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxHm9xMN_Mrv",
        "colab_type": "code",
        "outputId": "692df2f3-f810-4fed-8a34-3893e1574a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgDia5NuVVLb",
        "colab_type": "code",
        "outputId": "231fbe1d-4728-44a9-df4a-bcfe972f6187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip /content/drive/'My Drive'/'Colab Notebooks'/competition_CNN.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/competition_CNN.zip\n",
            "replace competition_CNN/hindi/.ipynb_checkpoints/PyTorch Data Loader Code-checkpoint.ipynb? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PeozigfFQ850",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#For converting the dataset to torchvision dataset format\n",
        "class VowelConsonantDataset(Dataset):\n",
        "    def __init__(self, file_path,train=True,transform=None):\n",
        "        print('__init__')\n",
        "        self.transform = transform\n",
        "        self.file_path=file_path\n",
        "        self.train=train\n",
        "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
        "        self.len = len(self.file_names)\n",
        "        print('Num files = ', self.len)\n",
        "        if self.train:\n",
        "            self.classes_mapping=self.get_classes()\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        #used in iter() function over DataLoader()\n",
        "        file_name=self.file_names[index]\n",
        "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
        "        if self.transform:\n",
        "            image_data = self.transform(image_data)\n",
        "        if self.train:\n",
        "            file_name_splitted=file_name.split(\"_\")\n",
        "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
        "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
        "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
        "            z1[Y1-10],z2[Y2]=1,1\n",
        "            label=torch.stack([z1,z2])\n",
        "\n",
        "            return image_data, label\n",
        "\n",
        "        else:\n",
        "            return image_data, file_name\n",
        "          \n",
        "    def pil_loader(self,path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "      \n",
        "    def get_classes(self):\n",
        "        classes=[]\n",
        "        for name in self.file_names:\n",
        "            name_splitted=name.split(\"_\")\n",
        "            classes.extend([name_splitted[0],name_splitted[1]])\n",
        "        classes=list(set(classes))\n",
        "        classes_mapping={}\n",
        "        for i,cl in enumerate(sorted(classes)):\n",
        "            classes_mapping[cl]=i\n",
        "        print(classes_mapping)\n",
        "        return classes_mapping\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJJ_MrEVQ_eX",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-BX7SIgS_bU",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X2cOje6hS_yA",
        "scrolled": false,
        "outputId": "61f8c332-9745-4cf8-a8f6-1d4bf3f8402e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        }
      },
      "source": [
        "%%time\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "full_data = VowelConsonantDataset(\"./competition_CNN/hindi/input/train/train\",train=True,transform=transform)\n",
        "train_size = int(0.8 * len(full_data))\n",
        "test_size = len(full_data) - train_size\n",
        "print(train_size, test_size)\n",
        "h_batch_size = 50\n",
        "\n",
        "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=h_batch_size, shuffle=True)\n",
        "'''\n",
        "tr_dataiter = iter(train_loader)\n",
        "tr_images, tr_labels = tr_dataiter.next()\n",
        "\n",
        "print(tr_images.shape, tr_labels.shape)\n",
        "print(tr_images[1].shape, tr_labels[1].shape)\n",
        "#print(np.nonzero(tr_labels[1][0]),np.nonzero(tr_labels[1][1]))\n",
        "\n",
        "\n",
        "npimg = tr_images[1].numpy().reshape((64,64,3))\n",
        "#plt.figure(figsize = (1,1))\n",
        "#plt.imshow(npimg)\n",
        "plt.imshow(npimg)\n",
        "plt.show()\n",
        "'''\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=h_batch_size, shuffle=True)\n",
        "\n",
        "class FFN_VC_Classifier(nn.Module):\n",
        "  \n",
        "  def __init__(self,p):\n",
        "    super().__init__()\n",
        "    torch.manual_seed(0)\n",
        "    self.net_common = nn.Sequential(\n",
        "        nn.Conv2d(3, 16, 9),\n",
        "        nn.Dropout(p=p),\n",
        "        nn.BatchNorm2d(num_features=16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, stride=2),  # (N, 20, 56, 56) -> (N,  20, 28, 28)\n",
        "        #nn.Dropout(p=p),\n",
        "          \n",
        "        nn.Conv2d(16, 8, 9, padding=(4,4)),\n",
        "        nn.Dropout(p=p),\n",
        "        nn.BatchNorm2d(num_features=8),\n",
        "        nn.ReLU(),\n",
        "        #nn.Conv2d(8, 8, 3, padding=(1,1)),\n",
        "        #nn.Dropout(p=p),\n",
        "        #nn.BatchNorm2d(num_features=8),\n",
        "        #nn.ReLU(),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        #nn.Dropout(p=p)\n",
        "    )\n",
        "    self.br1 = nn.Sequential(\n",
        "        #nn.Linear(225*8, 1024),\n",
        "        #nn.Dropout(p=p),\n",
        "        #nn.ReLU(),\n",
        "        #nn.Linear(1024, 256),\n",
        "        nn.Linear(196*8, 256),\n",
        "        nn.Dropout(p=p),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 10)\n",
        "        #nn.Softmax()\n",
        "    )\n",
        "    self.br2 = nn.Sequential(\n",
        "        #nn.Linear(225*8, 1024),\n",
        "        #nn.Dropout(p=p),\n",
        "        #nn.ReLU(),\n",
        "        #nn.Linear(1024, 256),\n",
        "        nn.Linear(196*8, 256),\n",
        "        nn.Dropout(p=p),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 10)\n",
        "        #nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    hinter = self.net_common(X)\n",
        "    hflat = hinter.view(hinter.size(0), -1)\n",
        "    o1 = self.br1(hflat)\n",
        "    o2 = self.br2(hflat)\n",
        "    #pred = torch.argmax(o1,dim=1)\n",
        "    #print(o1.shape, o2.shape, torch.cat([o1, o2], 1).shape)\n",
        "    C = torch.stack([o1,o2], dim=1)\n",
        "    return C\n",
        "\n",
        "net = FFN_VC_Classifier(0.3)  \n",
        "\n",
        "def evaluation(dataloader):\n",
        "    #total, correct = 0, 0\n",
        "    total, c1, c2, correct = 0, 0, 0, 0\n",
        "    for data in dataloader:\n",
        "        inputs, labels = data\n",
        "        #print('eval...\\n',np.shape(inputs),np.shape(labels))\n",
        "        #inputs = inputs.reshape([inputs.shape[0],1,4096])\n",
        "        outputs = net(inputs)\n",
        "        o1 = torch.argmax(outputs[:,0,:], dim=1)\n",
        "        o2 = torch.argmax(outputs[:,1,:], dim=1)\n",
        "        l1 = torch.argmax(labels[:,0,:], dim=1)\n",
        "        l2 = torch.argmax(labels[:,1,:], dim=1)\n",
        "        #print(np.shape(o1),np.shape(o2),np.shape(l1),np.shape(l2))\n",
        "        #_, pred = torch.max(outputs.data, 2)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        c1 += np.sum(o1.numpy() == l1.numpy())\n",
        "        c2 += np.sum(o2.numpy() == l2.numpy())\n",
        "        \n",
        "    correct = c1 + c2\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(net.parameters(), lr=0.0001)\n",
        "#opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.95)\n",
        "loss_arr = []\n",
        "loss_epoch_arr = []\n",
        "max_epochs = 20\n",
        "min_loss = 1000\n",
        "for epoch in range(max_epochs):\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        #inputs = inputs.reshape([inputs.shape[0],1,4096])\n",
        "        opt.zero_grad()\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        #print(outputs.shape)\n",
        "        o1 = outputs[:,0,:]\n",
        "        o2 = outputs[:,1,:]\n",
        "        labels_long = torch.tensor(labels, dtype=torch.long)\n",
        "        loss1 = loss_fn(o1, torch.argmax(labels_long[:,0,:], dim=1))\n",
        "        loss2 = loss_fn(o2, torch.argmax(labels_long[:,1,:], dim=1))\n",
        "        tot_loss = loss1 + loss2\n",
        "        if tot_loss < min_loss:\n",
        "            min_loss = tot_loss\n",
        "        #print(tot_loss)\n",
        "        #loss = loss_fn(outputs, labels)\n",
        "        tot_loss.backward()\n",
        "        opt.step()\n",
        "        \n",
        "        loss_arr.append(tot_loss.item())\n",
        "        del inputs, labels, outputs, o1, o2\n",
        "        torch.cuda.empty_cache()\n",
        "    print(tot_loss)\n",
        "    loss_epoch_arr.append(tot_loss.item())\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      net.eval()\n",
        "      print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (epoch, max_epochs, evaluation(validation_loader), evaluation(train_loader)))\n",
        "      net.train()\n",
        "    \n",
        "plt.plot(loss_epoch_arr)\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__\n",
            "Num files =  10000\n",
            "{'C0': 0, 'C1': 1, 'C2': 2, 'C3': 3, 'C4': 4, 'C5': 5, 'C6': 6, 'C7': 7, 'C8': 8, 'C9': 9, 'V0': 10, 'V1': 11, 'V2': 12, 'V3': 13, 'V4': 14, 'V5': 15, 'V6': 16, 'V7': 17, 'V8': 18, 'V9': 19}\n",
            "8000 2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(4.5830, grad_fn=<AddBackward0>)\n",
            "Epoch: 0/20, Test acc: 27.75, Train acc: 30.45\n",
            "tensor(4.3220, grad_fn=<AddBackward0>)\n",
            "Epoch: 1/20, Test acc: 31.75, Train acc: 35.16\n",
            "tensor(4.3451, grad_fn=<AddBackward0>)\n",
            "Epoch: 2/20, Test acc: 34.70, Train acc: 37.11\n",
            "tensor(4.1879, grad_fn=<AddBackward0>)\n",
            "Epoch: 3/20, Test acc: 36.20, Train acc: 42.36\n",
            "tensor(4.2646, grad_fn=<AddBackward0>)\n",
            "Epoch: 4/20, Test acc: 38.00, Train acc: 44.77\n",
            "tensor(4.0856, grad_fn=<AddBackward0>)\n",
            "Epoch: 5/20, Test acc: 41.55, Train acc: 48.42\n",
            "tensor(3.9345, grad_fn=<AddBackward0>)\n",
            "Epoch: 6/20, Test acc: 41.35, Train acc: 50.45\n",
            "tensor(4.1307, grad_fn=<AddBackward0>)\n",
            "Epoch: 7/20, Test acc: 42.85, Train acc: 50.99\n",
            "tensor(4.0875, grad_fn=<AddBackward0>)\n",
            "Epoch: 8/20, Test acc: 47.85, Train acc: 57.88\n",
            "tensor(3.9661, grad_fn=<AddBackward0>)\n",
            "Epoch: 9/20, Test acc: 49.55, Train acc: 60.42\n",
            "tensor(3.5580, grad_fn=<AddBackward0>)\n",
            "Epoch: 10/20, Test acc: 51.95, Train acc: 61.95\n",
            "tensor(3.6013, grad_fn=<AddBackward0>)\n",
            "Epoch: 11/20, Test acc: 54.15, Train acc: 64.11\n",
            "tensor(3.8370, grad_fn=<AddBackward0>)\n",
            "Epoch: 12/20, Test acc: 57.35, Train acc: 67.90\n",
            "tensor(3.9786, grad_fn=<AddBackward0>)\n",
            "Epoch: 13/20, Test acc: 60.30, Train acc: 71.62\n",
            "tensor(3.5603, grad_fn=<AddBackward0>)\n",
            "Epoch: 14/20, Test acc: 61.35, Train acc: 73.97\n",
            "tensor(3.3190, grad_fn=<AddBackward0>)\n",
            "Epoch: 15/20, Test acc: 62.35, Train acc: 75.39\n",
            "tensor(3.5080, grad_fn=<AddBackward0>)\n",
            "Epoch: 16/20, Test acc: 63.55, Train acc: 78.05\n",
            "tensor(3.2924, grad_fn=<AddBackward0>)\n",
            "Epoch: 17/20, Test acc: 67.45, Train acc: 82.67\n",
            "tensor(3.3173, grad_fn=<AddBackward0>)\n",
            "Epoch: 18/20, Test acc: 69.20, Train acc: 85.47\n",
            "tensor(3.5175, grad_fn=<AddBackward0>)\n",
            "Epoch: 19/20, Test acc: 69.60, Train acc: 86.14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD6TJXSmlPJAmd6WU8kCa3JVSygP9H3qBcmo8nCfuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 32min 2s, sys: 37.6 s, total: 32min 39s\n",
            "Wall time: 32min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uzv8q9j63A_L",
        "outputId": "29d80f4c-00d3-4527-c97e-955766da22bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "import pandas as pd\n",
        "test_data = VowelConsonantDataset(\"./competition_CNN/hindi/input/test/test\",train=False,transform=transform)\n",
        "b_s = 20\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=b_s,shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "submission_df = pd.read_csv('../competition_CNN/hindi/input/sample_submission.csv')\n",
        "for d in test_loader:\n",
        "    inputs, fn = d\n",
        "    #inputs, labels = d\n",
        "    #inputs = inputs.reshape([len(inputs),1,4096])\n",
        "    outputs = net(inputs)\n",
        "    o1 = torch.argmax(outputs[:,0,:], dim=1)\n",
        "    o2 = torch.argmax(outputs[:,1,:], dim=1)\n",
        "    olc = ['C']*b_s\n",
        "    olv = ['V']*b_s\n",
        "    ol = [\"{}{}_{}{}\".format(a_, b_, c_, d_) for a_, b_, c_, d_ in zip(olv,o2,olc,o1)]\n",
        "    i = 0\n",
        "    for name in fn:\n",
        "        j = int(name.split('.')[0])\n",
        "        submission_df.iat[j-1, 1] = ol[i]\n",
        "        i += 1\n",
        "submission_df.to_csv('./out.csv', index=False)    \n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__\n",
            "Num files =  10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-74e4c9047d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/sample_submission.csv' does not exist: b'../input/sample_submission.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l0HVEsRCBvjb",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}